<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<!-- <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"> -->
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Zelin Wu, Wu Zelin, TYUT, Taiyuan University of Technologhy"> 
<meta name="description" content="MaYue's Home">
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Yue Ma@THU</title>
</head>
<body>
<div id="layout-content" style="margin-top:25px">
 <a href="https://github.com/mayuelala" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#FD6C6C; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Wu Ze-lin </h1><h1>
				</h1></div>

				<h3>Ph.D Student</h3>
				<p>
					Taiyuan University of Technologhy <br>
					Taiyuan, China.<br>
					<br>
					Email: wuzelin0059 [at] link.tyut.edu.cn<br>
					
				</p>
				<p> <a href="https://scholar.google.com/citations?user=kwBR1ygAAAAJ&hl=zh-CN"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://www.linkedin.com/in/yue-ma-a991b425a/"><img src="./pic/LinkedIn.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/mayuelala"><img src="./pic/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://space.bilibili.com/358448816?spm_id_from=333.1007.0.0"><img src="./pic/bilibili.jpg" height="30px" style="margin-bottom:-3px"></a>
				</p>
			</td>
			<td>
<!-- 				<img src="./pic/my.png" border="0" width="240"><br> -->
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<h2>Biography</h2>
<p>
	I am a year-2 master student at <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>, under the supervision of <a href="https://www.sigs.tsinghua.edu.cn/lx/main.htm" target="_blank">Prof. Xiu Li</a>. 
	I obtained my B.Eng in Computer Science at <a href="https://www.tsinghua.edu.cn/en/index.htm">Taiyuan University of Technology</a> in 2021. 
	I studied in the <a href="http://mmlab.siat.ac.cn/">CUHK@MMLab in ShenZhen</a> led by Prof. <a href="https://scholar.google.com/citations?user=gFtI-8QAAAAJ&hl=en" target="_blank">Dr. Yu Qiao</a> . Also, I had a great time at <a href="https://www.tsinghua.edu.cn/">Baidu Research</a>.
	Currently, I am a research intern at <a href="https://ai.tencent.com/">Tencent AI Lab</a>, working closely with <a href="https://tianyu-yang.com/" target="_blank">Dr. Tianyu Yang</a>, <a href="https://ybsong00.github.io/" target="_blank">Dr. Yibing Song</a> and <a href="https://xinntao.github.io/" target="_blank">Dr. Xintao Wang</a>. 
</p>
<p>My research lies at the areas of computer vision and machine learning. 
	In particular, my current focus is mainly on video understanding (e.g., action recognition, temporal action detection), 
	unsupervised/self-supervised representation learning, cross-modal learning (e.g., combining vision and language). </p>



<h2>News</h2>
<div style="height: 240px; overflow: auto;">
<ul>
	<li>
		[02/2023] One paper <a herf="https://arxiv.org/abs/2302.05940">SemanticAC</a> about Audio Classification was accepted by <a herf="https://2023.ieeeicassp.org/">ICASSP 2023</a>!
	</li>
	<li>
		[12/2022] Awarded First-Class Scholarship of <a herf="https://www.tsinghua.edu.cn/">Tsinghua Shenzhen International Graduate School</a>!
	</li>
	<li>
		[11/2022] One paper about video-text pretraining with masked autoencoder is submitted to  <a href="https://cvpr2023.thecvf.com/CVPR">CVPR 2023</a>!
	</li>
	<li>
		[10/2022] One paper about semantics-assisted framework for audio classification is submitted to <a href="https://2023.ieeeicassp.org/">ICASSP 2023</a>!
	</li>
	<li>
		[09/2022] Attending <a href="https://2022.acmmm.org/">ACM MM 2022</a>, Welcome to chat!
	</li>
	<li>
		[09/2022] <a href="https://">My first paper</a> has been accepted for <i style="color: red; display: inline;">Oral Presentation</i> on ACM MM 2022 (Top 5%) !
	</li>
	<li>
		[05/2022] Joined <a href="https://ai.tencent.com/">Tencent AI Lab</a> as research intern !
	</li>
	<li>
		[03/2022] Awarded <a href="https://www.withzz.com/project/detail/99">Tencent Rhino-Bird Research Elite Program</a> from Tencent ! Only <i style="color: red; display: inline;">72</i> students in the world admitted to this program !
	</li>
	<li>
		[07/2021] Joined <a href="http://mmlab.siat.ac.cn/">CUHK@MMLab in ShenZhen</a> as research intern !
	</li>
	<li>
		[06/2021] Recommended to <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a> towards the MSc degree !
	</li>
	<li>
		[06/2021] Graduated from <a href="http://ccst.tyut.edu.cn/">Taiyuan University of Technology</a> !
	</li>
	<li>
		[01/2021] Joined <a href="https://www.tsinghua.edu.cn/">Baidu Research</a> as research intern. Started doing research on Computer Vision !
	</li>
</ul>
</div>


<h2> Selected Publications | <a href="https://scholar.google.com/citations?user=kwBR1ygAAAAJ&hl=zh-CN">Full List</a></h2>
<!--
<div style="height: 1440px; overflow: auto;">
-->
<table id="tbPublications" width="100%">
	<tbody>
	<td><b>/*Preprints*/</b>
	<p></p>
	</td>
	<tr>
	<tr>
		<td width="306">
		<img src="./indexpics/2022-simvtp-framework.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>SimVTP: Simple Video Text Pre-training with Masked Autoencoders</b></p>
		<p><b>Yue Ma</b>, Tianyu Yang, Ying Shan, Xiu Li</p>
		<em>arXiv preprint:2211.03490. 2022</em>
		<p> [<a href="https://arxiv.org/pdf/2211.03490">paper</a>] [<a href="https://github.com/mayuelala/SimVTP">code</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<!--########################-->
		
	<td><b>/*Conference*/</b>
	<p></p>
	</td>
	
	<tr>
		<td width="306">
		<img src="./indexpics/2023-icassp-audio.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>SemanticAC: Semantics-Assisted Framework for Audio Classification</b></p>
		<p>Yicheng Xiao*, <b>Yue Ma*</b>, Shuyan Li, Hantao Zhou, Ran Liao, Xiu Li (* equal contribution)</p>
		<em>IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), 2023. </em>
		<i></i>
		<p> [<a href="https://arxiv.org/abs/2302.05940">paper</a>] [<a href="https://github.com/mayuelala">code</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>
		<td width="306">
		<img src="./indexpics/2022-mm-graph.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Visual Knowledge Graph for Human Action Reasoning in Videos</b></p>
		<p><b>Yue Ma</b>, Yali Wang, Yue Wu, Ziyu Lyu, Siran Chen, Xiu Li, Yu Qiao</p>
		<em>The 30th ACM International Conference on Multimedia. (<b>ACM MM</b>), 2022. </em>
		<i><p style="color: red; display: inline;">(Oral Presentation)</p></i>
		<p> [<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548257">paper</a>] [<a href="https://github.com/mayuelala/AKU">code</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
		


</tbody></table>
<!--
</div>
-->


<h2>Industrial Experience</h2>
<table style="border-spacing:2px">
	
	<tbody>
	<tr><td> [12/2022] — Present, Research Intern, <a href="https://ai.tencent.com/">Tencent AI Lab</a>, hosted by <a href="https://xinntao.github.io/" target="_blank">Dr. Xintao Wang</a>  </td></tr>
	<tr><td> [05/2022] —  [11/2022], Research Intern, <a href="https://ai.tencent.com/">Tencent AI Lab</a>, hosted by <a href="https://tianyu-yang.com/" target="_blank">Dr. Tianyu Yang</a>  </td></tr>
	<tr><td> [07/2021] —  [05/2022], Research Intern, <a href="http://mmlab.siat.ac.cn/">CUHK@MMLab in ShenZhen</a>, hosted by <a href="https://scholar.google.com/citations?user=gFtI-8QAAAAJ&hl=en" target="_blank">Dr. Yu Qiao</a> </td></tr>
	<tr><td> [01/2021] —  [07/2022], Research Intern, <a href="https://www.tsinghua.edu.cn/">Baidu Research</a>, hosted by <a href="https://scholar.google.com/citations?user=T-YePFgAAAAJ&hl=zh-CN">ZhiKang Zou</a>  </td></tr>

	</tbody>
</table>



<h2>Honors &amp; Awards</h2>
<table style="border-spacing:2px">
	<tbody>
	<tr><td> [12/2022] First-Class Scholarship of <a herf="https://www.tsinghua.edu.cn/">Tsinghua Shenzhen International Graduate School</a>.</td></tr>
	<tr><td> [03/2022] <a href="https://www.withzz.com/project/detail/99">Tencent Rhino-Bird Research Elite Program</a>, only 72 students in the world admitted to this program.</td></tr>
	<tr><td> [09/2020] Scholarship for Academic Excellence of <a href="http://ccst.tyut.edu.cn/">Taiyuan University of Technology</a></td></tr>
	<tr><td> [06/2019] Excellent Scientific Student of <a href="http://ccst.tyut.edu.cn/">Taiyuan University of Technology</a></td></tr>
	<tr><td> [09/2019] Scholarship for Academic Excellence of <a href="http://ccst.tyut.edu.cn/">Taiyuan University of Technology</a></td></tr>
	<tr><td> [09/2018] Excellent Academic Progress Student of <a href="http://ccst.tyut.edu.cn/">Taiyuan University of Technology</a></td></tr>
	<tr><td> [06/2018] Scholarship for Academic Excellence of <a href="http://ccst.tyut.edu.cn/">Taiyuan University of Technology</a></td></tr>

	</tbody>
</table>


<!-- <h2>Professional Services</h2>
<ul>
	<li>	
	<b>Reviewers:</b><br>
	Computer Vision and Pattern Recognition (CVPR’22)<br>
	European Conference on Computer Vision (ECCV’22)<br>
	International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI’22)<br>
	Medical Imaging with Deep Learning (MIDL'22)<br>
	IEEE Transactions on Medical Imaging (TMI) <br>
	IEEE Journal of Biomedical and Health Informatics (J-BHI) <br>
	Information Fusion<br>
	Medical Physics<br>
	</li>


</ul> -->


</div>
</body></html>
